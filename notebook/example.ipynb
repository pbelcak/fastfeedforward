{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../fastfeedforward\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fff import FFF\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "entropy_effect = 0.10\n",
    "n_epochs = 5\n",
    "\n",
    "leaf_width = 16\n",
    "depth = 3\n",
    "activation = nn.ReLU()\n",
    "leaf_dropout = 0.0\n",
    "region_leak = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "from torchvision import datasets, transforms\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset_training = datasets.MNIST('data', download=True, train=True, transform=transform)\n",
    "dataloader_training = torch.utils.data.DataLoader(dataset_training, batch_size=batch_size, shuffle=True)\n",
    "dataset_testing = datasets.MNIST('data', download=True, train=False, transform=transform)\n",
    "dataloader_testing = torch.utils.data.DataLoader(dataset_testing, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the FFF model\n",
    "model = FFF(input_width=784, leaf_width=leaf_width, output_width=10, depth=depth, activation=activation, dropout=leaf_dropout, region_leak=region_leak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:19<00:00, 24.25it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "number of dimensions must be sparse_dim (2) + dense_dim (2), but got 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lexec\\Desktop\\fastfeedforward\\notebook\\example.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lexec/Desktop/fastfeedforward/notebook/example.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m testing_accuracies \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lexec/Desktop/fastfeedforward/notebook/example.ipynb#W4sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_images, batch_labels \u001b[39min\u001b[39;00m tqdm(dataloader_testing):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lexec/Desktop/fastfeedforward/notebook/example.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \toutput \u001b[39m=\u001b[39m model(batch_images\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m784\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lexec/Desktop/fastfeedforward/notebook/example.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \tloss \u001b[39m=\u001b[39m criterion(output, batch_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lexec/Desktop/fastfeedforward/notebook/example.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \taccuracy \u001b[39m=\u001b[39m (output\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m batch_labels)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\lexec\\anaconda3\\envs\\py39torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lexec\\Desktop\\fastfeedforward\\notebook\\../fastfeedforward\\fff.py:337\u001b[0m, in \u001b[0;36mFFF.forward\u001b[1;34m(self, x, return_entropies, use_hard_decisions)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39mif\u001b[39;00m use_hard_decisions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m use_hard_decisions:\n\u001b[0;32m    336\u001b[0m \t\u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot use soft decisions during evaluation.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 337\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_forward(x)\n",
      "File \u001b[1;32mc:\\Users\\lexec\\Desktop\\fastfeedforward\\notebook\\../fastfeedforward\\fff.py:381\u001b[0m, in \u001b[0;36mFFF.eval_forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    379\u001b[0m y_coordinates \u001b[39m=\u001b[39m leaves\u001b[39m.\u001b[39mlong()\n\u001b[0;32m    380\u001b[0m indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack((x_coordinates, y_coordinates), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\t\u001b[39m# (2, batch_size)\u001b[39;00m\n\u001b[1;32m--> 381\u001b[0m w1s \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msparse_coo_tensor(\n\u001b[0;32m    382\u001b[0m \tindices\u001b[39m=\u001b[39;49mindices,\n\u001b[0;32m    383\u001b[0m \tvalues\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw1s,\n\u001b[0;32m    384\u001b[0m \tsize\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_leaves, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_width, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleaf_width),\n\u001b[0;32m    385\u001b[0m \tdevice\u001b[39m=\u001b[39;49mx\u001b[39m.\u001b[39;49mdevice\n\u001b[0;32m    386\u001b[0m )\t\u001b[39m# (batch_size, self.input_width, self.leaf_width)\u001b[39;00m\n\u001b[0;32m    387\u001b[0m logits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(x\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m), w1s) \u001b[39m# (batch_size, 1, self.leaf_width)\u001b[39;00m\n\u001b[0;32m    388\u001b[0m logits\u001b[39m.\u001b[39mindex_add_(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, index\u001b[39m=\u001b[39mleaves, source\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1s) \u001b[39m# (batch_size, 1, self.leaf_width)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: number of dimensions must be sparse_dim (2) + dense_dim (2), but got 3"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "training_losses = []\n",
    "training_accuracies = []\n",
    "training_entropies = []\n",
    "epoch_testing_losses = []\n",
    "epoch_testing_accuracies = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in range(n_epochs):\n",
    "\tprint(\"Epoch\", epoch)\n",
    "\n",
    "\tmodel.train()\n",
    "\tfor batch_images, batch_labels in tqdm(dataloader_training):\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\toutput, node_entropies = model(batch_images.view(-1, 784), return_entropies=True)\n",
    "\t\tnode_entropy_mean = node_entropies.mean()\n",
    "\t\tloss = criterion(output, batch_labels) + entropy_effect * node_entropy_mean\n",
    "\t\taccuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
    "\n",
    "\t\ttraining_losses.append(loss.item())\n",
    "\t\ttraining_accuracies.append(accuracy.item())\n",
    "\t\ttraining_entropies.append(node_entropy_mean.item())\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\n",
    "\t# test the model\n",
    "\tmodel.eval()\n",
    "\ttesting_losses = []\n",
    "\ttesting_accuracies = []\n",
    "\tfor batch_images, batch_labels in tqdm(dataloader_testing):\n",
    "\t\toutput = model(batch_images.view(-1, 784))\n",
    "\t\tloss = criterion(output, batch_labels)\n",
    "\t\taccuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
    "\n",
    "\t\ttesting_losses.append(loss.item())\n",
    "\t\ttesting_accuracies.append(accuracy.item())\n",
    "\tepoch_testing_losses.append(sum(testing_losses) / len(testing_losses))\n",
    "\tepoch_testing_accuracies.append(sum(testing_accuracies) / len(testing_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses)\n",
    "plt.plot(training_accuracies)\n",
    "plt.plot(training_entropies)\n",
    "plt.legend([\"training loss\", \"training accuracy\", \"mean node entropy\"], loc=\"upper right\")\n",
    "plt.title(\"The evolution of training loss, accuracy, and mean node entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(testing_losses)\n",
    "plt.plot(testing_accuracies)\n",
    "plt.legend([\"testing loss\", \"testing accuracy\"], loc=\"upper right\")\n",
    "plt.title(\"The evolution of testing loss and accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
